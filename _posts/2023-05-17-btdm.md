---
layout: post
title: Bidirectional Temporal Diffusion Model for Temporally Consistent Human Animation
image: images/btdm_thumbnail.png
# categories: [HTML,Code]
excerpt: The technique for generating temporally coherent human animations. It uses bidirectional temporal modeling and a denoising diffusion model to reduce motion ambiguities and improve realism.
---
<p style="text-align:center">Tserendorj Adiya, Sanghun Kim<sup>1</sup>, Jung Eun Lee<sup>1</sup>, Jea Shin Yoon<sup>2</sup> and Hwasup Lim<sup>1</sup></p>
<p style="text-align:center"><sup>1</sup>Korea Institude of Science and Technology, <sup>2</sup>Adobe.</p>

<img src="../images/btdm_main.gif" alt="btdm main" />

<h3>Abstract</h3>
<hr>
We introduce a method to generate temporally coherent human animation from a single image, a video, or a random noise. This problem has been formulated as modeling of an auto-regressive generation, i.e., to regress past frames to decode future frames. However, such unidirectional generation is highly prone to motion drifting over time, generating unrealistic human animation with significant artifacts such as appearance distortion. We claim that bidirectional temporal modeling enforces temporal coherence on a generative network by largely suppressing the motion ambiguity of human appearance. To prove our claim, we design a novel human animation framework using a denoising diffusion model: a neural network learns to generate the image of a person by denoising temporal Gaussian noises whose intermediate results are cross-conditioned bidirectionally between consec utive frames. In the experiments, our method demonstrates strong performance compared to existing unidirectional approaches with realistic temporal coherence.

<h3>Overview</h3>
<hr>
<img src="../images/btdm_overview.png" alt="single image comp 1" />
<p style="text-align:center">Our bidirectional temporal diffusion model (BTDM) where the intermediate results are recursively cross-conditioned on consecutive frames at every denoising step.</p>

<h3>Comparison</h3>
<hr>
We compare BTDM to state-of-the-art image-to-animation methods: "Motion Representations for Articulated Animation" (Siarohin et al. 2021) and "Thin-Plate Spline Motion Model" (Zhao et al. 2022).
<!-- <p style="text-align:center"></p> -->
<br>
<br>
<p style="text-align:center">Comparison on UBC Fashion dataset</p>
<img src="../images/btdm_img2anim_ubc.gif" alt="img2anim_ubc" />
<br>
<br>
<p style="text-align:center">Comparison on Graphic Simulated dataset</p>
<img src="../images/btdm_img2anim_gs.gif" alt="img2anim_gs" />
<br>
<br>
We compare BTDM to state-of-the-art video-to-animation methods: "Video-to-video synthesis" (Wang et al. 2018), "Everybody dance now" (Chan et al. 2019), "High-fidelity neural human
motion transfer from monocular video" (Kappel et al. 2021), "Dance in the wild" (Wang et al. 2021) and "Learning motion-dependent appearance for high-fidelity rendering of dynamic
humans from a single camera" (Yoon et al. 2022)

<img src="../images/btdm_vid2anim.gif" alt="vid2anim" />
<br>
<br>
<br>
<br>
Here we show few generated animation from noise.
<img src="../images/btdm_noise2anim.gif" alt="noise2anim" />
<br>
<br>
<h3>Ablation Study</h3>
<hr>
<p style="text-align:center">We compare unidirectional and bidirectional model</p>
<img src="../images/btdm_uni_vs_bi.gif" alt="uni_vs_bi" />
<p style="text-align:center">We show effective of Recursive Sampling method for generating animation.</p>
<img src="../images/btdm_sampling.gif" alt="sampling" />
<p style="text-align:center">Comparison of number of images used for fine-tuning</p>
<img src="../images/btdm_nimg.gif" alt="nimg" />

<h3>Bibtex</h3>
<hr>
<div style="padding-left: 30px;">
    @article{<br>
    <div style="padding-left: 30px;">
        adiya2023bidirectional, <br>
        title={Bidirectional Temporal Diffusion Model for Temporally Consistent Human Animation},<br>
        author={Tserendorj Adiya, Sanghun Kim, Jung Eun Lee, Jea Shin Yoon and Hwasup Lim},<br>
        booktitle={arXiv preprint arxiv:2306.09329},<br>
        year={2023}<br>
    </div>
    }
</div>